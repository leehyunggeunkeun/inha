{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_0417.ipynb",
      "provenance": [],
      "mount_file_id": "1cDwFZvq6JzxgwmBWcnDbg1LpYB9Hx4GF",
      "authorship_tag": "ABX9TyMelvu1+ZJyh1cuXoqAhZ16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehyunggeunkeun/pytorch-study/blob/master/pytorch_0417_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDFaXy4pqCEA",
        "colab_type": "text"
      },
      "source": [
        "간단한 다중선형회귀 예제\n",
        "\n",
        "Iris data를 활용하여 sepal length, sepal width, petal length의 변화에 따른 petal width 구하기!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_holegnp-jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#필요한 라이브러리 불러오기 \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "df = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg-tVDx_ysUh",
        "colab_type": "code",
        "outputId": "05885cc2-877f-4406-d16f-8df787c06713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb6d8754570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhg5pXC_sW77",
        "colab_type": "text"
      },
      "source": [
        "데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tww9ALK2aol0",
        "colab_type": "code",
        "outputId": "c5c67ef1-500a-4e92-a4e8-36c5d1b253e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "# 데이터프레임형식으로 변환\n",
        "df=pd.DataFrame(data=df['data'],columns=df['feature_names'])\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0                  5.1               3.5                1.4               0.2\n",
              "1                  4.9               3.0                1.4               0.2\n",
              "2                  4.7               3.2                1.3               0.2\n",
              "3                  4.6               3.1                1.5               0.2\n",
              "4                  5.0               3.6                1.4               0.2\n",
              "..                 ...               ...                ...               ...\n",
              "145                6.7               3.0                5.2               2.3\n",
              "146                6.3               2.5                5.0               1.9\n",
              "147                6.5               3.0                5.2               2.0\n",
              "148                6.2               3.4                5.4               2.3\n",
              "149                5.9               3.0                5.1               1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kOaMIVboTlV",
        "colab_type": "code",
        "outputId": "f6bb70ac-e215-4a3f-d909-bcfb57efba9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "standard_df=df\n",
        "standard_df=standard_df.apply(lambda x: (x-x.mean())/x.std())\n",
        "standard_df['petal width (cm)']=df['petal width (cm)']\n",
        "standard_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.897674</td>\n",
              "      <td>1.015602</td>\n",
              "      <td>-1.335752</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.139200</td>\n",
              "      <td>-0.131539</td>\n",
              "      <td>-1.335752</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.380727</td>\n",
              "      <td>0.327318</td>\n",
              "      <td>-1.392399</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.501490</td>\n",
              "      <td>0.097889</td>\n",
              "      <td>-1.279104</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.018437</td>\n",
              "      <td>1.245030</td>\n",
              "      <td>-1.335752</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>1.034539</td>\n",
              "      <td>-0.131539</td>\n",
              "      <td>0.816859</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0.551486</td>\n",
              "      <td>-1.278680</td>\n",
              "      <td>0.703564</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.793012</td>\n",
              "      <td>-0.131539</td>\n",
              "      <td>0.816859</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.430722</td>\n",
              "      <td>0.786174</td>\n",
              "      <td>0.930154</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.068433</td>\n",
              "      <td>-0.131539</td>\n",
              "      <td>0.760211</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0            -0.897674          1.015602          -1.335752               0.2\n",
              "1            -1.139200         -0.131539          -1.335752               0.2\n",
              "2            -1.380727          0.327318          -1.392399               0.2\n",
              "3            -1.501490          0.097889          -1.279104               0.2\n",
              "4            -1.018437          1.245030          -1.335752               0.2\n",
              "..                 ...               ...                ...               ...\n",
              "145           1.034539         -0.131539           0.816859               2.3\n",
              "146           0.551486         -1.278680           0.703564               1.9\n",
              "147           0.793012         -0.131539           0.816859               2.0\n",
              "148           0.430722          0.786174           0.930154               2.3\n",
              "149           0.068433         -0.131539           0.760211               1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYQYBRBfi2Ml",
        "colab_type": "code",
        "outputId": "4f768170-2344-461b-ff16-173bd657e507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#150 x 4라는 아주 작은 데이터셋 \n",
        "#x는 모든행을 불러오고 마지막 petal width를 제외하고 불러오고, y는 모든행을 가진 petal width열만\n",
        "x,y=standard_df.values[:,:-1],standard_df.values[:,-1:]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 3), (150, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xJNiJZZd5M5",
        "colab_type": "text"
      },
      "source": [
        "커스텀 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsExa22dIHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#커스텀 데이터셋을 만드는 가장 기본적인 뼈대\n",
        "\n",
        "class Iris():\n",
        "    def __init__(self):\n",
        "        self.x_data = torch.FloatTensor(x)\n",
        "        self.y_data = torch.FloatTensor(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BanUfnOv1vXl",
        "colab_type": "code",
        "outputId": "0e36712f-d5d3-4111-cf71-35d4436ab0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#만약 CLASS로만 구현하고자 한다면\n",
        "\n",
        "'''class MultiLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear=nn.Linear(3,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model=MultiLinearRegression()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "\n",
        "nb_epochs=2000\n",
        "train_losses=[]\n",
        "for epoch in range(nb_epochs+1):\n",
        "    for batch_idx, samples in enumerate(dataloader):\n",
        "        x_train, y_train = samples\n",
        "        \n",
        "\n",
        "        prediction = model(x_train)\n",
        "        cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(cost.item())\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "            cost.item()\n",
        "             ))'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"class MultiLinearRegression(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.linear=nn.Linear(3,1)\\n\\n    def forward(self,x):\\n        return self.linear(x)\\n\\nmodel=MultiLinearRegression()\\n\\noptimizer = optim.SGD(model.parameters(), lr=1e-5)\\n\\n\\nnb_epochs=2000\\ntrain_losses=[]\\nfor epoch in range(nb_epochs+1):\\n    for batch_idx, samples in enumerate(dataloader):\\n        x_train, y_train = samples\\n        \\n\\n        prediction = model(x_train)\\n        cost = F.mse_loss(prediction, y_train)\\n\\n\\n\\n        optimizer.zero_grad()\\n        cost.backward()\\n        optimizer.step()\\n        train_losses.append(cost.item())\\n\\n\\n        if epoch % 100 == 0:\\n            print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\\n            epoch, nb_epochs, batch_idx+1, len(dataloader),\\n            cost.item()\\n             ))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqOAbLTGdIJz",
        "colab_type": "code",
        "outputId": "fac7410d-c38c-4d56-e5c5-71157ba1bbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset=Iris()\n",
        "\n",
        "#train /test data나누기\n",
        "\n",
        "train_test_ratio=0.8\n",
        "train_size=int(len(dataset)*train_test_ratio)\n",
        "test_size=len(dataset)-train_size\n",
        "\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset,[train_size,test_size])\n",
        "print(len(train_dataset), len(test_dataset))\n",
        "\n",
        "#train 120개 test 30개"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Kpx9gpdIMA",
        "colab_type": "code",
        "outputId": "60b3c06e-70b8-4289-ab82-1916b9afca6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(dataset),dataset[0]  #총 샘플의수 150개 0번째 샘플의 x는 [-0.897674,\t1.015602,\t-1.335752] ,\t0.2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, (tensor([-0.8977,  1.0156, -1.3358]), tensor([0.2000])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8hJBVCNpzIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader=DataLoader(dataset=train_dataset,batch_size=len(dataset)) \n",
        "test_dataloader=DataLoader(dataset=test_dataset,batch_size=len(dataset)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn9uNslOscza",
        "colab_type": "text"
      },
      "source": [
        "모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "538KEuXVdIPE",
        "colab_type": "code",
        "outputId": "1aea5c37-9d2b-4780-a0ba-7a51d59d3517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = nn.Linear(3,1)      #input 3 ouput 1\n",
        "print(list(model.parameters())) #초기화된 w,b값 확인\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.3888, -0.1955,  0.5641]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.0667], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q56QuH0_lvFN",
        "colab_type": "code",
        "outputId": "013ba842-f03d-424a-d3fe-3e1c266b7714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "nb_epochs=2000\n",
        "train_losses=[]\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "    for batch_idx, samples in enumerate(train_dataloader):\n",
        "        x_train, y_train = samples\n",
        "        \n",
        "\n",
        "        prediction = model(x_train)\n",
        "        cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(cost.item())\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print('Epoch {:4d}/{} Batch {}/{} Train Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, batch_idx+1, len(train_dataloader),\n",
        "            cost.item()\n",
        "             ))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Batch 1/1 Train Cost: 1.781373\n",
            "Epoch  100/2000 Batch 1/1 Train Cost: 1.774174\n",
            "Epoch  200/2000 Batch 1/1 Train Cost: 1.767006\n",
            "Epoch  300/2000 Batch 1/1 Train Cost: 1.759870\n",
            "Epoch  400/2000 Batch 1/1 Train Cost: 1.752765\n",
            "Epoch  500/2000 Batch 1/1 Train Cost: 1.745691\n",
            "Epoch  600/2000 Batch 1/1 Train Cost: 1.738648\n",
            "Epoch  700/2000 Batch 1/1 Train Cost: 1.731636\n",
            "Epoch  800/2000 Batch 1/1 Train Cost: 1.724653\n",
            "Epoch  900/2000 Batch 1/1 Train Cost: 1.717703\n",
            "Epoch 1000/2000 Batch 1/1 Train Cost: 1.710782\n",
            "Epoch 1100/2000 Batch 1/1 Train Cost: 1.703891\n",
            "Epoch 1200/2000 Batch 1/1 Train Cost: 1.697031\n",
            "Epoch 1300/2000 Batch 1/1 Train Cost: 1.690199\n",
            "Epoch 1400/2000 Batch 1/1 Train Cost: 1.683398\n",
            "Epoch 1500/2000 Batch 1/1 Train Cost: 1.676627\n",
            "Epoch 1600/2000 Batch 1/1 Train Cost: 1.669884\n",
            "Epoch 1700/2000 Batch 1/1 Train Cost: 1.663172\n",
            "Epoch 1800/2000 Batch 1/1 Train Cost: 1.656489\n",
            "Epoch 1900/2000 Batch 1/1 Train Cost: 1.649834\n",
            "Epoch 2000/2000 Batch 1/1 Train Cost: 1.643209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjG4MrtTEQII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4d4a58d0-94b4-4f27-f15e-9131ba64fc05"
      },
      "source": [
        "print(list(model.parameters())) #학습후 w와 b의 값 확인"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.3787, -0.1865,  0.5551]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.0167], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKYr3LNmFXPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bb9075b6-b203-4ad1-ecb2-2d89b687c2b2"
      },
      "source": [
        "#epoch에 따른 train_losses 변화\n",
        "\n",
        "plt.plot(train_losses)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnTp05G_sgbC",
        "colab_type": "text"
      },
      "source": [
        "테스트하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg5eGPX_sjc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aef4858-8ceb-4702-8d75-9cafc9386fe5"
      },
      "source": [
        "#테스트 하는 것이므로 torch.no_grad()구간 안에 있어야함.\n",
        "\n",
        "test_losses=[]\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch_idx, samples in enumerate(test_dataloader):\n",
        "        x_test, y_test = samples\n",
        "        prediction = model(x_test)\n",
        "        cost = F.mse_loss(prediction, y_test)\n",
        "        test_losses.append(cost.item())\n",
        "\n",
        "test_losses"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5568422079086304]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "600hnnZQpLr7",
        "colab_type": "code",
        "outputId": "77d4e617-1e15-4002-d0c6-939de026dfbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_var=torch.FloatTensor([[-0.897674,1.015602,-1.335752\t]]) #petal width가 0.2인 0번째 인덱스의 x값(정규화된)을 넣어봄\n",
        "pred_y=model(new_var)\n",
        "\n",
        "print('훈련 후 입력이 -0.897674,1.015602,-1.335752\t 일때의 예측값: ', pred_y)\n",
        "#0.2인데 -1.28이라 예측함 test오차만큼......"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 후 입력이 -0.897674,1.015602,-1.335752\t 일때의 예측값:  tensor([[-1.2875]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24xFjt1xrcGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}