{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_0420_이진분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkGW6PgPL8xAwxFlrKTHkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehyunggeunkeun/pytorch-study/blob/master/pytorch_0420_%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4ksDwGlXv1-",
        "colab_type": "text"
      },
      "source": [
        "데이터 불러오기 및 간단한 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZWExWXoXwch",
        "colab_type": "code",
        "outputId": "912c6a67-644a-485a-d5a5-0e5844d0878f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "#필요한 라이브러리\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine=load_wine()\n",
        "wine        \n",
        "\n",
        "#어떠한 데이터인지 확인 data , feature_names ,target, target_names "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
              " 'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "         1.065e+03],\n",
              "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "         1.050e+03],\n",
              "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "         1.185e+03],\n",
              "        ...,\n",
              "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "         8.350e+02],\n",
              "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "         8.400e+02],\n",
              "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "         5.600e+02]]),\n",
              " 'feature_names': ['alcohol',\n",
              "  'malic_acid',\n",
              "  'ash',\n",
              "  'alcalinity_of_ash',\n",
              "  'magnesium',\n",
              "  'total_phenols',\n",
              "  'flavanoids',\n",
              "  'nonflavanoid_phenols',\n",
              "  'proanthocyanins',\n",
              "  'color_intensity',\n",
              "  'hue',\n",
              "  'od280/od315_of_diluted_wines',\n",
              "  'proline'],\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2]),\n",
              " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCA9hVoX549",
        "colab_type": "code",
        "outputId": "52370e0f-2085-489c-b953-eb878d68ed73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "df=pd.DataFrame(data = wine['data'],columns = wine['feature_names'])  #df에 wine의 feature_names를 컬럼으로 wine의 data을 data값으로 불러옴\n",
        "df['target']=wine.target # target이라는 컬럼을 새로 만든다.\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  target\n",
              "0      14.23        1.71  2.43  ...                          3.92   1065.0       0\n",
              "1      13.20        1.78  2.14  ...                          3.40   1050.0       0\n",
              "2      13.16        2.36  2.67  ...                          3.17   1185.0       0\n",
              "3      14.37        1.95  2.50  ...                          3.45   1480.0       0\n",
              "4      13.24        2.59  2.87  ...                          2.93    735.0       0\n",
              "..       ...         ...   ...  ...                           ...      ...     ...\n",
              "173    13.71        5.65  2.45  ...                          1.74    740.0       2\n",
              "174    13.40        3.91  2.48  ...                          1.56    750.0       2\n",
              "175    13.27        4.28  2.26  ...                          1.56    835.0       2\n",
              "176    13.17        2.59  2.37  ...                          1.62    840.0       2\n",
              "177    14.13        4.10  2.74  ...                          1.60    560.0       2\n",
              "\n",
              "[178 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dloUqFt2uJL",
        "colab_type": "code",
        "outputId": "c02cef51-4084-4e17-f498-ad83dbd6169c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "#우리가 구하고자 하는것은 이진분류이므로, 이번에는 0과 1을 남기고 2를 삭제해보겠다.\n",
        "\n",
        "not2=df['target'].isin([0,1])   #not2라는 변수에 df['target'].isin([0,1])을 하면 0과1은 True 2는False값으로 저장\n",
        "df=df[not2]                     #이것을 df로 다시 묶어주면 True인 0과 1의 target값만 남게된다.\n",
        "df          "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>12.07</td>\n",
              "      <td>2.16</td>\n",
              "      <td>2.17</td>\n",
              "      <td>21.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.65</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.28</td>\n",
              "      <td>378.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>12.43</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.29</td>\n",
              "      <td>21.5</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.77</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.69</td>\n",
              "      <td>2.84</td>\n",
              "      <td>352.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>11.79</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.78</td>\n",
              "      <td>28.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.76</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.97</td>\n",
              "      <td>2.44</td>\n",
              "      <td>466.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>12.37</td>\n",
              "      <td>1.63</td>\n",
              "      <td>2.30</td>\n",
              "      <td>24.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.22</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.90</td>\n",
              "      <td>2.12</td>\n",
              "      <td>0.89</td>\n",
              "      <td>2.78</td>\n",
              "      <td>342.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>12.04</td>\n",
              "      <td>4.30</td>\n",
              "      <td>2.38</td>\n",
              "      <td>22.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2.57</td>\n",
              "      <td>580.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  target\n",
              "0      14.23        1.71  2.43  ...                          3.92   1065.0       0\n",
              "1      13.20        1.78  2.14  ...                          3.40   1050.0       0\n",
              "2      13.16        2.36  2.67  ...                          3.17   1185.0       0\n",
              "3      14.37        1.95  2.50  ...                          3.45   1480.0       0\n",
              "4      13.24        2.59  2.87  ...                          2.93    735.0       0\n",
              "..       ...         ...   ...  ...                           ...      ...     ...\n",
              "125    12.07        2.16  2.17  ...                          3.28    378.0       1\n",
              "126    12.43        1.53  2.29  ...                          2.84    352.0       1\n",
              "127    11.79        2.13  2.78  ...                          2.44    466.0       1\n",
              "128    12.37        1.63  2.30  ...                          2.78    342.0       1\n",
              "129    12.04        4.30  2.38  ...                          2.57    580.0       1\n",
              "\n",
              "[130 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny8HSlDbZSLo",
        "colab_type": "code",
        "outputId": "26973270-e2fc-4ef0-ba9b-f2ff1a23161c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "#더 좋은 결과값을 위해서 정규화를 해줌\n",
        "\n",
        "standard_df=df\n",
        "standard_df=standard_df.apply(lambda x: (x-x.mean())/x.std())\n",
        "standard_df['target']=df['target']      #위의식으로 인해 target값까지 정규화 되었으므로 target값은 df['target']으로 재설정\n",
        "standard_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.446858</td>\n",
              "      <td>-0.293280</td>\n",
              "      <td>0.301312</td>\n",
              "      <td>-0.936752</td>\n",
              "      <td>1.761871</td>\n",
              "      <td>0.508454</td>\n",
              "      <td>0.772603</td>\n",
              "      <td>-0.460466</td>\n",
              "      <td>0.996374</td>\n",
              "      <td>0.888945</td>\n",
              "      <td>-0.111994</td>\n",
              "      <td>2.032163</td>\n",
              "      <td>0.779851</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.287952</td>\n",
              "      <td>-0.213731</td>\n",
              "      <td>-0.674587</td>\n",
              "      <td>-2.230695</td>\n",
              "      <td>0.006501</td>\n",
              "      <td>0.233424</td>\n",
              "      <td>0.365970</td>\n",
              "      <td>-0.643806</td>\n",
              "      <td>-0.875481</td>\n",
              "      <td>0.113933</td>\n",
              "      <td>-0.052714</td>\n",
              "      <td>0.937809</td>\n",
              "      <td>0.737300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.242946</td>\n",
              "      <td>0.445383</td>\n",
              "      <td>1.108952</td>\n",
              "      <td>-0.054518</td>\n",
              "      <td>0.071515</td>\n",
              "      <td>0.508454</td>\n",
              "      <td>1.016583</td>\n",
              "      <td>-0.277126</td>\n",
              "      <td>1.960101</td>\n",
              "      <td>0.913548</td>\n",
              "      <td>-0.171275</td>\n",
              "      <td>0.453768</td>\n",
              "      <td>1.120264</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.604379</td>\n",
              "      <td>-0.020543</td>\n",
              "      <td>0.536874</td>\n",
              "      <td>-0.583858</td>\n",
              "      <td>0.851679</td>\n",
              "      <td>2.433670</td>\n",
              "      <td>1.355445</td>\n",
              "      <td>-0.827146</td>\n",
              "      <td>0.792509</td>\n",
              "      <td>2.217536</td>\n",
              "      <td>-1.179042</td>\n",
              "      <td>1.043036</td>\n",
              "      <td>1.957113</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.332958</td>\n",
              "      <td>0.706756</td>\n",
              "      <td>1.781986</td>\n",
              "      <td>0.651270</td>\n",
              "      <td>1.176748</td>\n",
              "      <td>0.508454</td>\n",
              "      <td>0.271089</td>\n",
              "      <td>0.547905</td>\n",
              "      <td>0.125313</td>\n",
              "      <td>0.077028</td>\n",
              "      <td>-0.111994</td>\n",
              "      <td>-0.051318</td>\n",
              "      <td>-0.156284</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>-0.983469</td>\n",
              "      <td>0.218102</td>\n",
              "      <td>-0.573632</td>\n",
              "      <td>0.651270</td>\n",
              "      <td>-0.968704</td>\n",
              "      <td>0.141747</td>\n",
              "      <td>0.216871</td>\n",
              "      <td>0.364565</td>\n",
              "      <td>-0.745748</td>\n",
              "      <td>-0.882510</td>\n",
              "      <td>-1.179042</td>\n",
              "      <td>0.685266</td>\n",
              "      <td>-1.169013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>-0.578414</td>\n",
              "      <td>-0.497833</td>\n",
              "      <td>-0.169812</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>-0.903690</td>\n",
              "      <td>0.398442</td>\n",
              "      <td>0.894593</td>\n",
              "      <td>0.547905</td>\n",
              "      <td>0.032647</td>\n",
              "      <td>-0.156706</td>\n",
              "      <td>-2.186808</td>\n",
              "      <td>-0.240725</td>\n",
              "      <td>-1.242769</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>-1.298511</td>\n",
              "      <td>0.184010</td>\n",
              "      <td>1.479121</td>\n",
              "      <td>2.856855</td>\n",
              "      <td>-0.513608</td>\n",
              "      <td>-0.720017</td>\n",
              "      <td>-0.338861</td>\n",
              "      <td>2.289636</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>-0.734889</td>\n",
              "      <td>-0.526957</td>\n",
              "      <td>-1.082536</td>\n",
              "      <td>-0.919377</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>-0.645923</td>\n",
              "      <td>-0.384192</td>\n",
              "      <td>-0.136160</td>\n",
              "      <td>1.680543</td>\n",
              "      <td>-0.773663</td>\n",
              "      <td>-0.554998</td>\n",
              "      <td>-0.054218</td>\n",
              "      <td>0.639575</td>\n",
              "      <td>0.273579</td>\n",
              "      <td>-1.276167</td>\n",
              "      <td>-1.001200</td>\n",
              "      <td>-0.366997</td>\n",
              "      <td>-1.271137</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>-1.017223</td>\n",
              "      <td>2.650008</td>\n",
              "      <td>0.133054</td>\n",
              "      <td>0.945348</td>\n",
              "      <td>-1.293772</td>\n",
              "      <td>-0.775023</td>\n",
              "      <td>-1.003029</td>\n",
              "      <td>0.822915</td>\n",
              "      <td>-0.745748</td>\n",
              "      <td>-0.980924</td>\n",
              "      <td>-1.594004</td>\n",
              "      <td>-0.808948</td>\n",
              "      <td>-0.595985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      alcohol  malic_acid  ...   proline  target\n",
              "0    1.446858   -0.293280  ...  0.779851       0\n",
              "1    0.287952   -0.213731  ...  0.737300       0\n",
              "2    0.242946    0.445383  ...  1.120264       0\n",
              "3    1.604379   -0.020543  ...  1.957113       0\n",
              "4    0.332958    0.706756  ... -0.156284       0\n",
              "..        ...         ...  ...       ...     ...\n",
              "125 -0.983469    0.218102  ... -1.169013       1\n",
              "126 -0.578414   -0.497833  ... -1.242769       1\n",
              "127 -1.298511    0.184010  ... -0.919377       1\n",
              "128 -0.645923   -0.384192  ... -1.271137       1\n",
              "129 -1.017223    2.650008  ... -0.595985       1\n",
              "\n",
              "[130 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-1qi51yZSNw",
        "colab_type": "code",
        "outputId": "2d58b542-4d61-4312-efcc-66ee3a6a5226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x,y에 정규화된 값들을 저장 \n",
        "\n",
        "x,y=standard_df.values[:,:-1],standard_df.values[:,-1:]\n",
        "x.shape,y.shape #input 13 output 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((130, 13), (130, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edkph1eSvlsi",
        "colab_type": "text"
      },
      "source": [
        "커스텀 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crwn8CXDZSSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#파이토치로 로지스틱 리그레션(이진분류) 구현하기\n",
        "\n",
        "#필요 라이브러리 불러오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSFMTNQSgiPv",
        "colab_type": "code",
        "outputId": "96e9af9d-10f1-4a4b-f703-2aedce906e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4965ecd230>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVKg5h3mZSUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#커스텀 데이터셋 만들때 항상필요....\n",
        "\n",
        "class Wine():\n",
        "    def __init__(self):\n",
        "        self.x_data = torch.FloatTensor(x)\n",
        "        self.y_data = torch.FloatTensor(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x, y\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rm426xEgnA4",
        "colab_type": "code",
        "outputId": "eba5ff7a-2a21-478e-f153-ba9b4c868d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset=Wine()\n",
        "\n",
        "train_test_ratio=0.8\n",
        "train_size=int(len(dataset)*train_test_ratio)\n",
        "test_size=len(dataset)-train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset,[train_size,test_size])\n",
        "print(len(train_dataset), len(test_dataset))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnNXv3Qc59tM",
        "colab_type": "code",
        "outputId": "f81fda13-416b-44b4-c5bb-5de441370f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataset[0]  #0번쨰샘플의 x는 1.4469, -0.2933,  0.3013, -0.9368,  1.7619,  0.5085,  0.7726, -0.4605, 0.9964,  0.8889, -0.1120,  2.0322,  0.7799,  y는 0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.4469, -0.2933,  0.3013, -0.9368,  1.7619,  0.5085,  0.7726, -0.4605,\n",
              "          0.9964,  0.8889, -0.1120,  2.0322,  0.7799]), tensor([0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHEwEHvwwNTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader=DataLoader(dataset=train_dataset,batch_size=len(dataset)) \n",
        "test_loader=DataLoader(dataset=test_dataset,batch_size=len(dataset)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcn_9-vxgnDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear=nn.Linear(13,1)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.sigmoid(self.linear(x)) #선형회귀 되어 나온값에 시그모이드를 씌워준다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6czmz_GewUZV",
        "colab_type": "text"
      },
      "source": [
        "모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izjzs4aPgnFZ",
        "colab_type": "code",
        "outputId": "3e7e441f-0dc9-4d29-d437-0896de971657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model=BinaryClassifier()\n",
        "print(list(model.parameters())) #초기화된 w,b값 확인\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2575, -0.1722,  0.0602,  0.2393,  0.1838,  0.1729,  0.1971,  0.1754,\n",
            "          0.0716, -0.1897, -0.2329, -0.1271, -0.0323]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1700], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLLr6LH7gnHd",
        "colab_type": "code",
        "outputId": "676c4100-e85f-4bb6-8b33-fbfde9e2ee62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "nb_epochs=2000\n",
        "\n",
        "train_losses=[]\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "    for batch_idx, samples in enumerate(train_loader):\n",
        "        x_train, y_train = samples\n",
        "        \n",
        "\n",
        "        hypothesis = model(x_train)\n",
        "        cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(cost.item())\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print('Epoch {:4d}/{} Batch {}/{} Train Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, batch_idx+1, len(train_loader),\n",
        "            cost.item()\n",
        "             ))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Batch 1/1 Train Cost: 0.789128\n",
            "Epoch  100/2000 Batch 1/1 Train Cost: 0.347904\n",
            "Epoch  200/2000 Batch 1/1 Train Cost: 0.240727\n",
            "Epoch  300/2000 Batch 1/1 Train Cost: 0.191310\n",
            "Epoch  400/2000 Batch 1/1 Train Cost: 0.161669\n",
            "Epoch  500/2000 Batch 1/1 Train Cost: 0.141420\n",
            "Epoch  600/2000 Batch 1/1 Train Cost: 0.126491\n",
            "Epoch  700/2000 Batch 1/1 Train Cost: 0.114921\n",
            "Epoch  800/2000 Batch 1/1 Train Cost: 0.105633\n",
            "Epoch  900/2000 Batch 1/1 Train Cost: 0.097977\n",
            "Epoch 1000/2000 Batch 1/1 Train Cost: 0.091537\n",
            "Epoch 1100/2000 Batch 1/1 Train Cost: 0.086029\n",
            "Epoch 1200/2000 Batch 1/1 Train Cost: 0.081255\n",
            "Epoch 1300/2000 Batch 1/1 Train Cost: 0.077070\n",
            "Epoch 1400/2000 Batch 1/1 Train Cost: 0.073365\n",
            "Epoch 1500/2000 Batch 1/1 Train Cost: 0.070057\n",
            "Epoch 1600/2000 Batch 1/1 Train Cost: 0.067084\n",
            "Epoch 1700/2000 Batch 1/1 Train Cost: 0.064393\n",
            "Epoch 1800/2000 Batch 1/1 Train Cost: 0.061944\n",
            "Epoch 1900/2000 Batch 1/1 Train Cost: 0.059705\n",
            "Epoch 2000/2000 Batch 1/1 Train Cost: 0.057647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo6CrVB8Ii0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8b3398c7-9ee8-4bad-f5f5-9bd05761892c"
      },
      "source": [
        "print(list(model.parameters())) #학습후 w와 b의 값 확인"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-1.0625, -0.4436, -0.7904,  0.9468, -0.1684, -0.0566, -0.1894,  0.2090,\n",
            "          0.0443, -1.0599, -0.0087, -0.4862, -1.3659]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2040], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNToCuhrv5mj",
        "colab_type": "code",
        "outputId": "5c05e19a-5aba-4cef-8b74-de23e01fe33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjqkrFAYv7mc",
        "colab_type": "text"
      },
      "source": [
        "테스트하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DYb-WmrIotT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "866629a8-8150-4cc2-ce2c-7822c2ff3732"
      },
      "source": [
        "test_losses=[]\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch_idx, samples in enumerate(test_loader):\n",
        "        x_test, y_test = samples\n",
        "        prediction = model(x_test)\n",
        "        cost = F.mse_loss(prediction, y_test)\n",
        "        test_losses.append(cost.item())\n",
        "\n",
        "test_losses"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.009651756845414639]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T4PJnvoIovf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4bfb032-e38a-4a3c-a30e-1a26bd8ec6b6"
      },
      "source": [
        "new_var=torch.FloatTensor([[14.23,1.71,2.43,15.6,127.0,2.80,3.06,0.28,2.29,5.64,1.04,3.92,1065.0]]) #y가 0인 0번째 인덱스의 x값(정규화된)을 넣어봄\n",
        "pred_y=model(new_var)\n",
        "\n",
        "print('훈련 후 입력이 14.23,1.71,2.43,15.6,127.0,2.80,3.06,0.28,2.29,5.64,1.04,3.92,1065.0\t 일때의 예측값: ', pred_y)\n",
        "# 0.5보다 작으므로 0이다 잘나옴...."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 후 입력이 14.23,1.71,2.43,15.6,127.0,2.80,3.06,0.28,2.29,5.64,1.04,3.92,1065.0\t 일때의 예측값:  tensor([[0.]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWhlQy4rIoxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLY9C26EIoz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzPIzIxyIo2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L3UOmBfIo4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}