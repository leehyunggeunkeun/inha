{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_0420_이진분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyFQzEb+OZL0m1JgCCKnhx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehyunggeunkeun/pytorch-study/blob/master/pytorch_0420_%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4ksDwGlXv1-",
        "colab_type": "text"
      },
      "source": [
        "데이터 불러오기 및 간단한 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZWExWXoXwch",
        "colab_type": "code",
        "outputId": "56252db1-dfad-44ab-9413-87cfcc170725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "#필요한 라이브러리\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine=load_wine()\n",
        "wine        \n",
        "\n",
        "#어떠한 데이터인지 확인 data , feature_names ,target, target_names "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
              " 'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "         1.065e+03],\n",
              "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "         1.050e+03],\n",
              "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "         1.185e+03],\n",
              "        ...,\n",
              "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "         8.350e+02],\n",
              "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "         8.400e+02],\n",
              "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "         5.600e+02]]),\n",
              " 'feature_names': ['alcohol',\n",
              "  'malic_acid',\n",
              "  'ash',\n",
              "  'alcalinity_of_ash',\n",
              "  'magnesium',\n",
              "  'total_phenols',\n",
              "  'flavanoids',\n",
              "  'nonflavanoid_phenols',\n",
              "  'proanthocyanins',\n",
              "  'color_intensity',\n",
              "  'hue',\n",
              "  'od280/od315_of_diluted_wines',\n",
              "  'proline'],\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2]),\n",
              " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCA9hVoX549",
        "colab_type": "code",
        "outputId": "adaf4a57-0c28-47dc-d110-00d46362f17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "df=pd.DataFrame(data = wine['data'],columns = wine['feature_names'])  #df에 wine의 feature_names를 컬럼으로 wine의 data을 data값으로 불러옴\n",
        "df['target']=wine.target # target이라는 컬럼을 새로 만든다.\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  target\n",
              "0      14.23        1.71  2.43  ...                          3.92   1065.0       0\n",
              "1      13.20        1.78  2.14  ...                          3.40   1050.0       0\n",
              "2      13.16        2.36  2.67  ...                          3.17   1185.0       0\n",
              "3      14.37        1.95  2.50  ...                          3.45   1480.0       0\n",
              "4      13.24        2.59  2.87  ...                          2.93    735.0       0\n",
              "..       ...         ...   ...  ...                           ...      ...     ...\n",
              "173    13.71        5.65  2.45  ...                          1.74    740.0       2\n",
              "174    13.40        3.91  2.48  ...                          1.56    750.0       2\n",
              "175    13.27        4.28  2.26  ...                          1.56    835.0       2\n",
              "176    13.17        2.59  2.37  ...                          1.62    840.0       2\n",
              "177    14.13        4.10  2.74  ...                          1.60    560.0       2\n",
              "\n",
              "[178 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dloUqFt2uJL",
        "colab_type": "code",
        "outputId": "5e804091-2cd6-49a8-cd81-99ea09067b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "#우리가 구하고자 하는것은 이진분류이므로, 이번에는 0과 1을 남기고 2를 삭제해보겠다.\n",
        "\n",
        "not2=df['target'].isin([0,1])   #not2라는 변수에 df['target'].isin([0,1])을 하면 0과1은 True 2는False값으로 저장\n",
        "df=df[not2]                     #이것을 df로 다시 묶어주면 True인 0과 1의 target값만 남게된다.\n",
        "df          "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>12.07</td>\n",
              "      <td>2.16</td>\n",
              "      <td>2.17</td>\n",
              "      <td>21.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.65</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.28</td>\n",
              "      <td>378.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>12.43</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.29</td>\n",
              "      <td>21.5</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.77</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.69</td>\n",
              "      <td>2.84</td>\n",
              "      <td>352.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>11.79</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.78</td>\n",
              "      <td>28.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.76</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.97</td>\n",
              "      <td>2.44</td>\n",
              "      <td>466.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>12.37</td>\n",
              "      <td>1.63</td>\n",
              "      <td>2.30</td>\n",
              "      <td>24.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.22</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.90</td>\n",
              "      <td>2.12</td>\n",
              "      <td>0.89</td>\n",
              "      <td>2.78</td>\n",
              "      <td>342.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>12.04</td>\n",
              "      <td>4.30</td>\n",
              "      <td>2.38</td>\n",
              "      <td>22.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2.57</td>\n",
              "      <td>580.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  target\n",
              "0      14.23        1.71  2.43  ...                          3.92   1065.0       0\n",
              "1      13.20        1.78  2.14  ...                          3.40   1050.0       0\n",
              "2      13.16        2.36  2.67  ...                          3.17   1185.0       0\n",
              "3      14.37        1.95  2.50  ...                          3.45   1480.0       0\n",
              "4      13.24        2.59  2.87  ...                          2.93    735.0       0\n",
              "..       ...         ...   ...  ...                           ...      ...     ...\n",
              "125    12.07        2.16  2.17  ...                          3.28    378.0       1\n",
              "126    12.43        1.53  2.29  ...                          2.84    352.0       1\n",
              "127    11.79        2.13  2.78  ...                          2.44    466.0       1\n",
              "128    12.37        1.63  2.30  ...                          2.78    342.0       1\n",
              "129    12.04        4.30  2.38  ...                          2.57    580.0       1\n",
              "\n",
              "[130 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny8HSlDbZSLo",
        "colab_type": "code",
        "outputId": "b4ea1701-c2ab-4882-f93b-14f80b97cbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "#더 좋은 결과값을 위해서 정규화를 해줌\n",
        "\n",
        "standard_df=df\n",
        "standard_df=standard_df.apply(lambda x: (x-x.mean())/x.std())\n",
        "standard_df['target']=df['target']      #위의식으로 인해 target값까지 정규화 되었으므로 target값은 df['target']으로 재설정\n",
        "standard_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.446858</td>\n",
              "      <td>-0.293280</td>\n",
              "      <td>0.301312</td>\n",
              "      <td>-0.936752</td>\n",
              "      <td>1.761871</td>\n",
              "      <td>0.508454</td>\n",
              "      <td>0.772603</td>\n",
              "      <td>-0.460466</td>\n",
              "      <td>0.996374</td>\n",
              "      <td>0.888945</td>\n",
              "      <td>-0.111994</td>\n",
              "      <td>2.032163</td>\n",
              "      <td>0.779851</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.287952</td>\n",
              "      <td>-0.213731</td>\n",
              "      <td>-0.674587</td>\n",
              "      <td>-2.230695</td>\n",
              "      <td>0.006501</td>\n",
              "      <td>0.233424</td>\n",
              "      <td>0.365970</td>\n",
              "      <td>-0.643806</td>\n",
              "      <td>-0.875481</td>\n",
              "      <td>0.113933</td>\n",
              "      <td>-0.052714</td>\n",
              "      <td>0.937809</td>\n",
              "      <td>0.737300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.242946</td>\n",
              "      <td>0.445383</td>\n",
              "      <td>1.108952</td>\n",
              "      <td>-0.054518</td>\n",
              "      <td>0.071515</td>\n",
              "      <td>0.508454</td>\n",
              "      <td>1.016583</td>\n",
              "      <td>-0.277126</td>\n",
              "      <td>1.960101</td>\n",
              "      <td>0.913548</td>\n",
              "      <td>-0.171275</td>\n",
              "      <td>0.453768</td>\n",
              "      <td>1.120264</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.604379</td>\n",
              "      <td>-0.020543</td>\n",
              "      <td>0.536874</td>\n",
              "      <td>-0.583858</td>\n",
              "      <td>0.851679</td>\n",
              "      <td>2.433670</td>\n",
              "      <td>1.355445</td>\n",
              "      <td>-0.827146</td>\n",
              "      <td>0.792509</td>\n",
              "      <td>2.217536</td>\n",
              "      <td>-1.179042</td>\n",
              "      <td>1.043036</td>\n",
              "      <td>1.957113</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.332958</td>\n",
              "      <td>0.706756</td>\n",
              "      <td>1.781986</td>\n",
              "      <td>0.651270</td>\n",
              "      <td>1.176748</td>\n",
              "      <td>0.508454</td>\n",
              "      <td>0.271089</td>\n",
              "      <td>0.547905</td>\n",
              "      <td>0.125313</td>\n",
              "      <td>0.077028</td>\n",
              "      <td>-0.111994</td>\n",
              "      <td>-0.051318</td>\n",
              "      <td>-0.156284</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>-0.983469</td>\n",
              "      <td>0.218102</td>\n",
              "      <td>-0.573632</td>\n",
              "      <td>0.651270</td>\n",
              "      <td>-0.968704</td>\n",
              "      <td>0.141747</td>\n",
              "      <td>0.216871</td>\n",
              "      <td>0.364565</td>\n",
              "      <td>-0.745748</td>\n",
              "      <td>-0.882510</td>\n",
              "      <td>-1.179042</td>\n",
              "      <td>0.685266</td>\n",
              "      <td>-1.169013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>-0.578414</td>\n",
              "      <td>-0.497833</td>\n",
              "      <td>-0.169812</td>\n",
              "      <td>0.798309</td>\n",
              "      <td>-0.903690</td>\n",
              "      <td>0.398442</td>\n",
              "      <td>0.894593</td>\n",
              "      <td>0.547905</td>\n",
              "      <td>0.032647</td>\n",
              "      <td>-0.156706</td>\n",
              "      <td>-2.186808</td>\n",
              "      <td>-0.240725</td>\n",
              "      <td>-1.242769</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>-1.298511</td>\n",
              "      <td>0.184010</td>\n",
              "      <td>1.479121</td>\n",
              "      <td>2.856855</td>\n",
              "      <td>-0.513608</td>\n",
              "      <td>-0.720017</td>\n",
              "      <td>-0.338861</td>\n",
              "      <td>2.289636</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>-0.734889</td>\n",
              "      <td>-0.526957</td>\n",
              "      <td>-1.082536</td>\n",
              "      <td>-0.919377</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>-0.645923</td>\n",
              "      <td>-0.384192</td>\n",
              "      <td>-0.136160</td>\n",
              "      <td>1.680543</td>\n",
              "      <td>-0.773663</td>\n",
              "      <td>-0.554998</td>\n",
              "      <td>-0.054218</td>\n",
              "      <td>0.639575</td>\n",
              "      <td>0.273579</td>\n",
              "      <td>-1.276167</td>\n",
              "      <td>-1.001200</td>\n",
              "      <td>-0.366997</td>\n",
              "      <td>-1.271137</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>-1.017223</td>\n",
              "      <td>2.650008</td>\n",
              "      <td>0.133054</td>\n",
              "      <td>0.945348</td>\n",
              "      <td>-1.293772</td>\n",
              "      <td>-0.775023</td>\n",
              "      <td>-1.003029</td>\n",
              "      <td>0.822915</td>\n",
              "      <td>-0.745748</td>\n",
              "      <td>-0.980924</td>\n",
              "      <td>-1.594004</td>\n",
              "      <td>-0.808948</td>\n",
              "      <td>-0.595985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      alcohol  malic_acid  ...   proline  target\n",
              "0    1.446858   -0.293280  ...  0.779851       0\n",
              "1    0.287952   -0.213731  ...  0.737300       0\n",
              "2    0.242946    0.445383  ...  1.120264       0\n",
              "3    1.604379   -0.020543  ...  1.957113       0\n",
              "4    0.332958    0.706756  ... -0.156284       0\n",
              "..        ...         ...  ...       ...     ...\n",
              "125 -0.983469    0.218102  ... -1.169013       1\n",
              "126 -0.578414   -0.497833  ... -1.242769       1\n",
              "127 -1.298511    0.184010  ... -0.919377       1\n",
              "128 -0.645923   -0.384192  ... -1.271137       1\n",
              "129 -1.017223    2.650008  ... -0.595985       1\n",
              "\n",
              "[130 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-1qi51yZSNw",
        "colab_type": "code",
        "outputId": "95b197b0-ebf1-48a1-fa14-4d3dcbd2d3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x,y에 정규화된 값들을 저장 \n",
        "\n",
        "x,y=standard_df.values[:,:-1],standard_df.values[:,-1:]\n",
        "x.shape,y.shape #input 13 output 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((130, 13), (130, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edkph1eSvlsi",
        "colab_type": "text"
      },
      "source": [
        "커스텀 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crwn8CXDZSSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#파이토치로 로지스틱 리그레션(이진분류) 구현하기\n",
        "\n",
        "#필요 라이브러리 불러오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSFMTNQSgiPv",
        "colab_type": "code",
        "outputId": "c5c00259-dd15-4ecf-d19d-5a29ded76443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f72ccd5cf50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVKg5h3mZSUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#커스텀 데이터셋 만들때 항상필요....\n",
        "\n",
        "class Wine():\n",
        "    def __init__(self):\n",
        "        self.x_data = torch.FloatTensor(x)\n",
        "        self.y_data = torch.FloatTensor(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x, y\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rm426xEgnA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "edc6573c-8ece-4838-d79d-1418a6b2eec7"
      },
      "source": [
        "dataset=Wine()\n",
        "\n",
        "train_val_ratio=0.8\n",
        "train_size=int(len(dataset)*train_val_ratio)\n",
        "val_size=len(dataset)-train_size\n",
        "print(train_size,val_size)\n",
        "\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "print(len(train_dataset), len(val_dataset))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104 26\n",
            "104 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnNXv3Qc59tM",
        "colab_type": "code",
        "outputId": "3d367cc6-177f-4093-f111-ff8002de72d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataset[0]  #0번쨰샘플의 x는 1.4469, -0.2933,  0.3013, -0.9368,  1.7619,  0.5085,  0.7726, -0.4605, 0.9964,  0.8889, -0.1120,  2.0322,  0.7799,  y는 0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.4469, -0.2933,  0.3013, -0.9368,  1.7619,  0.5085,  0.7726, -0.4605,\n",
              "          0.9964,  0.8889, -0.1120,  2.0322,  0.7799]), tensor([0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHEwEHvwwNTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader=DataLoader(dataset=train_dataset,batch_size=len(dataset),shuffle=True) \n",
        "val_loader=DataLoader(dataset=val_dataset,batch_size=len(dataset),shuffle=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcn_9-vxgnDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear=nn.Linear(13,1)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.sigmoid(self.linear(x)) #선형회귀 되어 나온값에 시그모이드를 씌워준다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6czmz_GewUZV",
        "colab_type": "text"
      },
      "source": [
        "모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izjzs4aPgnFZ",
        "colab_type": "code",
        "outputId": "fcb24b92-1dce-46c6-9409-e088fa48d658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model=BinaryClassifier()\n",
        "print(list(model.parameters())) #초기화된 w,b값 확인\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2575, -0.1722,  0.0602,  0.2393,  0.1838,  0.1729,  0.1971,  0.1754,\n",
            "          0.0716, -0.1897, -0.2329, -0.1271, -0.0323]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1700], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLLr6LH7gnHd",
        "colab_type": "code",
        "outputId": "dc6cb396-e1f1-4ccc-c8e3-b200780db0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#validataion set 나누니 확실히 cost가 줄어든다.\n",
        "\n",
        "nb_epochs=2000\n",
        "train_losses=[]\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "    for batch_idx, samples in enumerate(train_loader):\n",
        "        x_train, y_train = samples\n",
        "        \n",
        "\n",
        "        prediction = model(x_train)\n",
        "        cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(cost.item())\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print('Epoch {:4d}/{} Batch {}/{} Train Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, batch_idx+1, len(train_loader),\n",
        "            cost.item()\n",
        "             ))\n",
        "            \n",
        "    for batch_idx, samples in enumerate(val_loader):\n",
        "        x_val, y_val = samples\n",
        "\n",
        "        prediction = model(x_val)\n",
        "        cost = F.mse_loss(prediction, y_val)\n",
        "\n",
        "        val_losses.append(cost.item())\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print('Epoch {:4d}/{} Batch {}/{} Validation Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, batch_idx+1, len(val_loader),\n",
        "            cost.item()\n",
        "             ))\n",
        "            print('-'*50)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Batch 1/1 Train Cost: 0.294952\n",
            "Epoch    0/2000 Batch 1/1 Validation Cost: 0.317359\n",
            "--------------------------------------------------\n",
            "Epoch  100/2000 Batch 1/1 Train Cost: 0.153109\n",
            "Epoch  100/2000 Batch 1/1 Validation Cost: 0.157749\n",
            "--------------------------------------------------\n",
            "Epoch  200/2000 Batch 1/1 Train Cost: 0.102505\n",
            "Epoch  200/2000 Batch 1/1 Validation Cost: 0.099455\n",
            "--------------------------------------------------\n",
            "Epoch  300/2000 Batch 1/1 Train Cost: 0.079221\n",
            "Epoch  300/2000 Batch 1/1 Validation Cost: 0.073330\n",
            "--------------------------------------------------\n",
            "Epoch  400/2000 Batch 1/1 Train Cost: 0.065716\n",
            "Epoch  400/2000 Batch 1/1 Validation Cost: 0.058921\n",
            "--------------------------------------------------\n",
            "Epoch  500/2000 Batch 1/1 Train Cost: 0.056749\n",
            "Epoch  500/2000 Batch 1/1 Validation Cost: 0.049859\n",
            "--------------------------------------------------\n",
            "Epoch  600/2000 Batch 1/1 Train Cost: 0.050283\n",
            "Epoch  600/2000 Batch 1/1 Validation Cost: 0.043647\n",
            "--------------------------------------------------\n",
            "Epoch  700/2000 Batch 1/1 Train Cost: 0.045359\n",
            "Epoch  700/2000 Batch 1/1 Validation Cost: 0.039123\n",
            "--------------------------------------------------\n",
            "Epoch  800/2000 Batch 1/1 Train Cost: 0.041462\n",
            "Epoch  800/2000 Batch 1/1 Validation Cost: 0.035677\n",
            "--------------------------------------------------\n",
            "Epoch  900/2000 Batch 1/1 Train Cost: 0.038287\n",
            "Epoch  900/2000 Batch 1/1 Validation Cost: 0.032961\n",
            "--------------------------------------------------\n",
            "Epoch 1000/2000 Batch 1/1 Train Cost: 0.035640\n",
            "Epoch 1000/2000 Batch 1/1 Validation Cost: 0.030761\n",
            "--------------------------------------------------\n",
            "Epoch 1100/2000 Batch 1/1 Train Cost: 0.033395\n",
            "Epoch 1100/2000 Batch 1/1 Validation Cost: 0.028938\n",
            "--------------------------------------------------\n",
            "Epoch 1200/2000 Batch 1/1 Train Cost: 0.031462\n",
            "Epoch 1200/2000 Batch 1/1 Validation Cost: 0.027399\n",
            "--------------------------------------------------\n",
            "Epoch 1300/2000 Batch 1/1 Train Cost: 0.029776\n",
            "Epoch 1300/2000 Batch 1/1 Validation Cost: 0.026081\n",
            "--------------------------------------------------\n",
            "Epoch 1400/2000 Batch 1/1 Train Cost: 0.028292\n",
            "Epoch 1400/2000 Batch 1/1 Validation Cost: 0.024936\n",
            "--------------------------------------------------\n",
            "Epoch 1500/2000 Batch 1/1 Train Cost: 0.026973\n",
            "Epoch 1500/2000 Batch 1/1 Validation Cost: 0.023931\n",
            "--------------------------------------------------\n",
            "Epoch 1600/2000 Batch 1/1 Train Cost: 0.025791\n",
            "Epoch 1600/2000 Batch 1/1 Validation Cost: 0.023039\n",
            "--------------------------------------------------\n",
            "Epoch 1700/2000 Batch 1/1 Train Cost: 0.024725\n",
            "Epoch 1700/2000 Batch 1/1 Validation Cost: 0.022242\n",
            "--------------------------------------------------\n",
            "Epoch 1800/2000 Batch 1/1 Train Cost: 0.023757\n",
            "Epoch 1800/2000 Batch 1/1 Validation Cost: 0.021525\n",
            "--------------------------------------------------\n",
            "Epoch 1900/2000 Batch 1/1 Train Cost: 0.022875\n",
            "Epoch 1900/2000 Batch 1/1 Validation Cost: 0.020874\n",
            "--------------------------------------------------\n",
            "Epoch 2000/2000 Batch 1/1 Train Cost: 0.022066\n",
            "Epoch 2000/2000 Batch 1/1 Validation Cost: 0.020281\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNToCuhrv5mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ba57d0f7-5277-48b2-fd6b-0f0107ac3b44"
      },
      "source": [
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(val_losses, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjqkrFAYv7mc",
        "colab_type": "text"
      },
      "source": [
        "예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZexO9_tv9vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#잠깐 근데 x_test값은 어떻게 나누지???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcD_6gmmixMl",
        "colab_type": "code",
        "outputId": "abe298a1-f4d5-4e6b-f09b-3355d8ac884e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "print(list(model.parameters())) #학습후 w와 b의 값 확인\n",
        "\n",
        "#epoch에 따른 train_losses 변화\n",
        "\n",
        "plt.plot(train_losses)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.5752, -0.3157, -0.5022,  0.6147, -0.0816, -0.0113, -0.0959,  0.1651,\n",
            "          0.0327, -0.7521, -0.0668, -0.3459, -0.8622]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0978], requires_grad=True)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}